{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "feb87f6e",
   "metadata": {},
   "source": [
    "## Uploading CSV Data to MongoDB\n",
    "\n",
    "In this project, we will be uploading CSV data to MongoDB. The data is located in the `data` folder. <br>\n",
    "The `data` folder is something like this:\n",
    "\n",
    "```\n",
    ".\n",
    "└── data/\n",
    "    ├── class_A/\n",
    "    │   ├── gyro/\n",
    "    |   |   |── class_A_01.csv\n",
    "    |   |   |── class_A_02.csv\n",
    "    │   ├── accelerometer/\n",
    "    |   |   |── class_A_01.csv\n",
    "    |   |   |── class_A_02.csv\n",
    "    │   └──\n",
    "    ├── class_B/\n",
    "    │   ├── gyro/\n",
    "    |   |   |── class_B_01.csv\n",
    "    |   |   |── class_B_02.csv\n",
    "    │   ├── accelerometer/\n",
    "    |   |   |── class_B_01.csv\n",
    "    |   |   |── class_B_02.csv\n",
    "    └── class ...\n",
    "```\n",
    "\n",
    "To upload this data to MongoDB, we will write a Python script that reads in each CSV file, transforms the data as necessary, and uploads it to the database. We will use the PyMongo library to interact with the database.\n",
    "\n",
    "Here are the high-level steps we will take:\n",
    "\n",
    "1. Iterate through the class folders in the `data` directory.\n",
    "2. For each class folder, iterate through the `gyro` and `accelerometer` subfolders.\n",
    "3. Read in the CSV files using the `csv` library.\n",
    "4. Transform the data as necessary, such as converting timestamps or normalizing values.\n",
    "5. Upload the data to the corresponding MongoDB collection using PyMongo.\n",
    "\n",
    "By following these steps, we will be able to upload all of our CSV data to MongoDB and prepare it for further analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1a34708",
   "metadata": {},
   "source": [
    "## Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e970c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for yaml handling\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb4f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client': 'mongodb://localhost:27017/', 'db': 'aiot_course', 'col': 'sensor_readings', 'order': ['x-axis (g)', 'y-axis (g)', 'z-axis (g)', 'x-axis (deg/s)', 'y-axis (deg/s)', 'z-axis (deg/s)'], 'rename': ['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z'], 'data_path': 'PATH TO THE DATASET', 'single_instance_path': 'PATH TO INSTANCE', 'sliding_window': {'ws': 30, 'overlap': 15, 'w_type': 'hann', 'w_center': True, 'print_stats': False}, 'x_number': 2, 'filter': {'order': 5, 'wn': 0.1, 'type': 'lowpass'}, 'PCA': {'n_comp': None}, 'classifier': {'SVC': {'C': None, 'kernel': 'rbf', 'gamma': None}}, 'fine_tune': {'param_grid': [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}], 'cv': 5, 'verbose': 1}, 'fit': {'epochs': None, 'batch': None, 'verbose': 'auto'}}\n"
     ]
    }
   ],
   "source": [
    "config_path = \"config.yml\"\n",
    "\n",
    "with open(config_path) as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65bac888",
   "metadata": {},
   "source": [
    "## MongoDB database instantiation\n",
    "\n",
    "The relevant information for the MongoDB client connection, the database name, and collection name is located in the configuration file.\n",
    "\n",
    "```\n",
    "# DB Connection with the uri (host)\n",
    "client: \"mongodb://localhost:27017/\"\n",
    "\n",
    "# db name\n",
    "db: \"aiot_course\"\n",
    "\n",
    "# db collection\n",
    "col: \"NAME YOUR COLLECTION\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cc2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for hanlding the MongoDB client\n",
    "import pymongo\n",
    "# import library for retrieving datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dbbbe9f",
   "metadata": {},
   "source": [
    "### Create the database\n",
    "\n",
    "To create a database in MongoDB, start by creating a MongoClient object, then specify a connection URL with the correct ip address and the name of the database you want to create.\n",
    "\n",
    "MongoDB will create the database if it does not exist, and make a connection to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdbb888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(config[\"client\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "203c2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[config[\"db\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0772e744",
   "metadata": {},
   "source": [
    "### Instantiate the collection\n",
    "\n",
    "To create a collection in MongoDB, use database object and specify the name of the collection you want to create.\n",
    "\n",
    "MongoDB will create the collection if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9937a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db[config[\"col\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcde222",
   "metadata": {},
   "source": [
    "Initially, no collection will be shown in MongoDB before you enter the first document!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b5cd593",
   "metadata": {},
   "source": [
    "## Create the data collection\n",
    "\n",
    "Uploading the gathered data to MongoDB collection. The data directory structure should be as follows:\n",
    "\n",
    "```\n",
    ".\n",
    "└── data/\n",
    "    ├── class_A/\n",
    "    │   ├── data_A_01.csv\n",
    "    │   ├── data_A_02.csv\n",
    "    │   └── ..\n",
    "    ├── class_B/\n",
    "    │   ├── data_B_01.csv\n",
    "    │   ├── data_B_02.csv\n",
    "    │   └── .\n",
    "    └── class ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622636fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for hanlding the csv data and transformations\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9532ede2",
   "metadata": {},
   "source": [
    "Get data path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912f079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "print(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a981a220",
   "metadata": {},
   "source": [
    "List all files in a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd476759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['α', 'β', 'γ', 'δ']\n"
     ]
    }
   ],
   "source": [
    "classes_folders_list = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
    "print(classes_folders_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8075f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print files in folder\n",
    "folder_path = os.path.join(data_path, classes_folders_list[0])\n",
    "files_in_folder = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "print(files_in_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c65d2961",
   "metadata": {},
   "source": [
    "Each document in the MongoDB database should have the following schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"data\": {\n",
    "    \"acc_x\": [\"array\", \"of\", \"values\"],\n",
    "    \"acc_y\": [\"array\", \"of\", \"values\"],\n",
    "    \"acc_z\": [\"array\", \"of\", \"values\"],\n",
    "    \"gyr_x\": [\"array\", \"of\", \"values\"],\n",
    "    \"gyr_y\": [\"array\", \"of\", \"values\"],\n",
    "    \"gyr_z\": [\"array\", \"of\", \"values\"]\n",
    "  },\n",
    "  \"label\": \"The label of the instance\",\n",
    "  \"datetime\": \"MongoDB datetime object (it can be generated with the datetime.datetime.now() function\"\n",
    "}\n",
    "```\n",
    "\n",
    "Accordingly, if you are using gyroscope or both accelerometer and gyroscope, the following order and naming of the sensor keys should be defined:\n",
    "\n",
    "* for gyroscope: `gyr_x`, `gyr_y`, `gyr_z` for the three axes\n",
    "* for accelerometer and gyroscope: `acc_x`, `acc_y`, `acc_z`, `gyr_x`, `gyr_y`, `gyr_z` for the six axes\n",
    "\n",
    "**Note: Be careful, the document is mandatory to have the aforementioned schema, in order to argue and proceed with the rest of the processes later on, in data engineering, plotting, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc16310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import df_rebase, df_rebase_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "115f2ae5",
   "metadata": {},
   "source": [
    "## Provide the code to upload the data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c8d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classes_folders_list:\n",
    "    gyro_path = data_path + \"/\" + item + \"/gyro\"\n",
    "    accel_path = data_path + \"/\" + item + \"/accel\"\n",
    "    \n",
    "    gyro_files = [f for f in os.listdir(gyro_path) if os.path.isfile(os.path.join(gyro_path, f))]\n",
    "    accel_files = [f for f in os.listdir(accel_path) if os.path.isfile(os.path.join(accel_path, f))]\n",
    "\n",
    "    # for accel_file in accel_files:\n",
    "    #     accel_df = pd.read_csv(accel_path + \"/\" + accel_file)\n",
    "    #     final_df = accel_df[config[\"order\"]]\n",
    "    #     final_df = final_df.rename(columns= dict(zip(config[\"order\"], config[\"rename\"])))  # rename the columns\n",
    "\n",
    "    #     data_dict = final_df.to_dict('list')\n",
    "    #     data_dict = {k: v for k, v in data_dict.items()}\n",
    "    #     doc = {\n",
    "    #         'data': data_dict,\n",
    "    #         'label': item,\n",
    "    #         'datetime': accel_df['time (03:00)'][0].replace(\"T\", \" \")\n",
    "    #     }\n",
    "    #     col.insert_one(doc)\n",
    "\n",
    "\n",
    "    for gyro_file, accel_file in zip(gyro_files, accel_files):\n",
    "        gyro_df = pd.read_csv(gyro_path + \"/\" + gyro_file)\n",
    "        accel_df = pd.read_csv(accel_path + \"/\" + accel_file)\n",
    "        \n",
    "        final_df = df_rebase(accel_df,gyro_df, config[\"order\"], config[\"rename\"])\n",
    "\n",
    "\n",
    "        # print(final_df.columns)\n",
    "\n",
    "        data_dict = final_df.to_dict('list')\n",
    "        data_dict = {k: v for k, v in data_dict.items()}\n",
    "\n",
    "        doc = {\n",
    "            'data': data_dict,\n",
    "            'label': item,\n",
    "            'datetime': gyro_df['time (03:00)'][0].replace(\"T\", \" \")\n",
    "        }\n",
    "\n",
    "        # print doc as json\n",
    "        # print(json.dumps(doc, indent=4))\n",
    "\n",
    "\n",
    "        # insert data to MongoDB\n",
    "        col.insert_one(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
